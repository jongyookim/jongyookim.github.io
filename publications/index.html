<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Multimedia AI Lab </title> <meta name="author" content="Multimedia AI Lab"> <meta name="description" content="Journal and conference publications"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon_128.png?ace3065a2426099ad17378689954309d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jongyookim.github.io/publications/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand symbol"> <img src="/assets/img/icon_128.png" alt="MMAI Lab" width="30" height="30"> </div> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Multimedia AI</span> Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">contact </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">Journal and conference publications</p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div id="leeDoubleReverseDiffusion2024" class="col-sm-10"> <div class="title">Double Reverse Diffusion for Realistic Garment Reconstruction from Images</div> <div class="author"> Jeonghaeng Lee, Duc Nguyen, <em>Jongyoo Kim</em>, Jiwoo Kang, and Sanghoon Lee </div> <div class="periodical"> <em>Engineering Applications of Artificial Intelligence</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Creating realistic digital 3D avatars has been getting more attention thanks to the introduction of new multimedia formats such as augmented and virtual reality. An important factor making avatars realistic is clothes. In this paper, we investigate a new method to reconstruct realistic garments from a set of images and body information. Early methods working on realistic images struggle to faithfully reconstruct the garment details. As deep learning is increasingly applied to geometric data which can conveniently represent garments, we devise a novel deep learning-based solution to the garment reconstruction problem. We offer a new perspective on the reconstruction problem and treat it as a reversion of the smoothing diffusion process. To achieve this goal, we propose to deform the smoothed human mesh into a clothed human via a Double Reverse Diffusion (DReD) process. For the first reverse diffusion, we introduce a novel operator called Graph Long Short-Term Memory (GraphLSTM) which recursively diffuses features to produce a deformed mesh by modeling the relationships between vertices. Then, the output mesh can be repeatedly upsampled and deformed by the above pipeline to obtain finer garment details, which can be seen as another reverse diffusion process. To obtain features for the reverse diffusion, we extract pixel-aligned features transferred from images and explore to incorporate the visibility of garments from the image viewpoints. Through detailed experiments on two public datasets, we demonstrate that DReD synthesizes more realistic wrinkled garments with lower errors and offers faster inference than previous methods.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div id="huangFreeEnricherEnrichingFace2023" class="col-sm-10"> <div class="title">FreeEnricher: Enriching Face Landmarks without Additional Cost</div> <div class="author"> Yangyu Huang, Xi Chen, <em>Jongyoo Kim</em>, Hao Yang, Chong Li, Jiaolong Yang, and Dong Chen </div> <div class="periodical"> <em>In AAAI Conference on Artificial Intelligence</em> , Jan 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimMNETMusicDrivenPluralistic2023" class="col-sm-10"> <div class="title">MNET++: Music-Driven Pluralistic Dancing Toward Multiple Dance Genre Synthesis</div> <div class="author"> Jinwoo Kim, Beom Kwon, <em>Jongyoo Kim</em>, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Numerous task-specific variants of autoregressive networks have been developed for dance generation. Nonetheless, a severe limitation remains in that all existing algorithms can return repeated patterns for a given initial pose, which may be inferior. We examine and analyze several key challenges of previous works, and propose variations in both model architecture (namely MNET++) and training methods to address these. In particular, we devise the beat synchronizer and dance synthesizer. First, generated dance should be locally and globally consistent with given music beats, circumvent repetitive patterns, and look realistic. To achieve this, the beat synchronizer implicitly catches the rhythm enabling it to stay in sync with the music as it dances. Then, the dance synthesizer infers the dance motions in a seamless patch-by-patch manner conditioned by music. Second, to generate diverse dance lines, adversarial learning is performed by leveraging the transformer architecture. Furthermore, MNET++ learns a dance genre-aware latent representation that is scalable for multiple domains to provide fine-grained user control according to the dance genre. Compared with the state-of-the-art methods, our method synthesizes plausible and diverse outputs according to multiple dance genres as well as generates remarkable dance sequences qualitatively and quantitatively.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div id="gaoMPSNeRFGeneralizable3D2022" class="col-sm-10"> <div class="title">MPS-NeRF: Generalizable 3D Human Rendering from Multiview Images</div> <div class="author"> Xiangjun Gao, Jiaolong Yang, <em>Jongyoo Kim</em>, Sida Peng, Zicheng Liu, and Xin Tong </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="nguyenSingleimage3DReconstruction2022" class="col-sm-10"> <div class="title">Single-Image 3-D Reconstruction: Rethinking Point Cloud Deformation</div> <div class="author"> Anh-Duc Nguyen, Seonghwa Choi, Woojae Kim, <em>Jongyoo Kim</em>, Heeseok Oh, Jiwoo Kang, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Transactions on Neural Networks and Learning Systems</em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div id="huangADNetLeveragingErrorbias2021" class="col-sm-10"> <div class="title">ADNet: Leveraging Error-Bias towards Normal Direction in Face Alignment</div> <div class="author"> Yangyu Huang, Hao Yang, Chong Li, <em>Jongyoo Kim</em>, and Fangyun Wei </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision (ICCV)</em> , Dec 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimDiverseAdjustableVersatile2021" class="col-sm-10"> <div class="title">Diverse and Adjustable Versatile Image Enhancer</div> <div class="author"> Woojae Kim, Anh-Duc Nguyen, Jinwoo Kim, <em>Jongyoo Kim</em>, Heeseok Oh, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Access</em>, Dec 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimLearningHighFidelityFace2021" class="col-sm-10"> <div class="title">Learning High-Fidelity Face Texture Completion Without Complete Face Texture</div> <div class="author"> <em>Jongyoo Kim</em>, Jiaolong Yang, and Xin Tong </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision (ICCV)</em> , Dec 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div id="nguyenVideoFrameSynthesis2019" class="col-sm-10"> <div class="title">Video Frame Synthesis Via Plug-and-Play Deep Locally Temporal Embedding</div> <div class="author"> Anh-Duc Nguyen, Woojae Kim, <em>Jongyoo Kim</em>, Weisi Lin, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Access</em>, Dec 2019 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div id="kimDeepBlindImage2018" class="col-sm-10"> <div class="title">Deep Blind Image Quality Assessment by Learning Sensitivity Map</div> <div class="author"> <em>Jongyoo Kim</em>, Woojae Kim, and Sanghoon Lee </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Dec 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimDeepCNNbasedBlind2018" class="col-sm-10"> <div class="title">Deep CNN-based Blind Image Quality Predictor</div> <div class="author"> <em>Jongyoo Kim</em>, Anh-Duc Nguyen, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Transactions on Neural Networks and Learning Systems</em>, Dec 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimDeepVideoQuality2018" class="col-sm-10"> <div class="title">Deep Video Quality Assessor: From Spatio-Temporal Visual Sensitivity to a Convolutional Neural Aggregation Network</div> <div class="author"> Woojae Kim, <em>Jongyoo Kim</em>, Sewoong Ahn, Jinwoo Kim, and Sanghoon Lee </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , Dec 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimMultipleLevelFeaturebased2018" class="col-sm-10"> <div class="title">Multiple Level Feature-Based Universal Blind Image Quality Assessment Model</div> <div class="author"> <em>Jongyoo Kim</em>, Anh-Duc Nguyen, Sewoong Ahn, Chong Luo, and Sanghoon Lee </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> , Dec 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="nguyenDeepVisualSaliency2018" class="col-sm-10"> <div class="title">Deep Visual Saliency on Stereoscopic Images</div> <div class="author"> Anh-Duc Nguyen, <em>Jongyoo Kim</em>, Heeseok Oh, Haksub Kim, Weisi Lin, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Transactions on Image Processing</em>, Dec 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="nguyenVideoFrameInterpolation2018" class="col-sm-10"> <div class="title">Video Frame Interpolation by Plug-and-Play Deep Locally Linear Embedding</div> <div class="author"> Anh-Duc Nguyen, Woojae Kim, <em>Jongyoo Kim</em>, and Sanghoon Lee </div> <div class="periodical"> <em>arXiv preprint arXiv:1807.01462</em>, Dec 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div id="kimDeepBlindImage2017" class="col-sm-10"> <div class="title">Deep Blind Image Quality Assessment by Employing FR-IQA</div> <div class="author"> <em>Jongyoo Kim</em>, and Sanghoon Lee </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> , Dec 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimDeepConvolutionalNeural2017" class="col-sm-10"> <div class="title">Deep Convolutional Neural Models for Picture-Quality Prediction: Challenges and Solutions to Data-Driven Image Quality Assessment</div> <div class="author"> <em>Jongyoo Kim</em>, Hui Zeng, Deepti Ghadiyaram, Sanghoon Lee, Lei Zhang, and Alan C Bovik </div> <div class="periodical"> <em>IEEE Signal Processing Magazine</em>, Dec 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimDeepLearningHuman2017" class="col-sm-10"> <div class="title">Deep Learning of Human Visual Sensitivity in Image Quality Assessment Framework</div> <div class="author"> <em>Jongyoo Kim</em>, and Sanghoon Lee </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em> , Dec 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimQualityAssessmentPerceptual2017" class="col-sm-10"> <div class="title">Quality Assessment of Perceptual Crosstalk on Two-View Auto-Stereoscopic Displays</div> <div class="author"> <em>Jongyoo Kim</em>, Taewan Kim, Sanghoon Lee, and Alan Conrad Bovik </div> <div class="periodical"> <em>IEEE Transactions on Image Processing</em>, Dec 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="leeIdentificationFrameworkPrintscan2017" class="col-sm-10"> <div class="title">An Identification Framework for Print-Scan Books in a Large Database</div> <div class="author"> Sang-Hoon Lee, <em>Jongyoo Kim</em>, and Sanghoon Lee </div> <div class="periodical"> <em>Information sciences</em>, Dec 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="ohBlindDeepS3D2017" class="col-sm-10"> <div class="title">Blind Deep S3D Image Quality Evaluation via Local to Global Feature Aggregation</div> <div class="author"> Heeseok Oh, Sewoong Ahn, <em>Jongyoo Kim</em>, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Transactions on Image Processing</em>, Dec 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="ohEnhancementVisualComfort2017" class="col-sm-10"> <div class="title">Enhancement of Visual Comfort and Sense of Presence on Stereoscopic 3D Images</div> <div class="author"> Heeseok Oh, <em>Jongyoo Kim</em>, Jinwoo Kim, Taewan Kim, Sanghoon Lee, and Alan Conrad Bovik </div> <div class="periodical"> <em>IEEE Transactions on Image Processing</em>, Dec 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div id="kimBlindSharpnessPrediction2016" class="col-sm-10"> <div class="title">Blind Sharpness Prediction for Ultrahigh-Definition Video Based on Human Visual Resolution</div> <div class="author"> Haksub Kim, <em>Jongyoo Kim</em>, Taegeun Oh, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, Dec 2016 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimFullyDeepBlind2016" class="col-sm-10"> <div class="title">Fully Deep Blind Image Quality Predictor</div> <div class="author"> <em>Jongyoo Kim</em>, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Journal of selected topics in signal processing</em>, Dec 2016 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimNoreferencePerceptualSharpness2016" class="col-sm-10"> <div class="title">No-Reference Perceptual Sharpness Assessment for Ultra-High-Definition Images</div> <div class="author"> Woojae Kim, Haksub Kim, Heeseok Oh, <em>Jongyoo Kim</em>, and Sanghoon Lee </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> , Dec 2016 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimPerceptualCrosstalkPrediction2016" class="col-sm-10"> <div class="title">Perceptual Crosstalk Prediction on Autostereoscopic 3D Display</div> <div class="author"> Taewan Kim, <em>Jongyoo Kim</em>, SeongYong Kim, Sungho Cho, and Sanghoon Lee </div> <div class="periodical"> <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, Dec 2016 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kwonFrameworkImplementationImagebased2016" class="col-sm-10"> <div class="title">Framework Implementation of Image-Based Indoor Localization System Using Parallel Distributed Computing</div> <div class="author"> Beom Kwon, Donghyun Jeon, <em>Jongyoo Kim</em>, Junghwan Kim, Doyoung Kim, Hyewon Song, and Sanghoon Lee </div> <div class="periodical"> <em>The Journal of Korean Institute of Communications and Information Sciences</em>, Dec 2016 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div id="kimImplementationOmnidirectionalHuman2015" class="col-sm-10"> <div class="title">Implementation of an Omnidirectional Human Motion Capture System Using Multiple Kinect Sensors</div> <div class="author"> Junghwan Kim, Inwoong Lee, <em>Jongyoo Kim</em>, and Sanghoon Lee </div> <div class="periodical"> <em>IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences</em>, Dec 2015 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kimVideoSharpnessPrediction2015" class="col-sm-10"> <div class="title">Video Sharpness Prediction Based on Motion Blur Analysis</div> <div class="author"> <em>Jongyoo Kim</em>, Junghwan Kim, Woojae Kim, Jisoo Lee, and Sanghoon Lee </div> <div class="periodical"> <em>In IEEE International Conference on Multimedia and Expo (ICME)</em> , Dec 2015 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="kwonImplementationHumanAction2015" class="col-sm-10"> <div class="title">Implementation of Human Action Recognition System Using Multiple Kinect Sensors</div> <div class="author"> Beom Kwon, Doyoung Kim, Junghwan Kim, Inwoong Lee, <em>Jongyoo Kim</em>, Heeseok Oh, Haksub Kim, and Sanghoon Lee </div> <div class="periodical"> <em>In Advances in Multimedia Information Processing–PCM 2015</em> , Dec 2015 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div id="oh3DVisualDiscomfort2015" class="col-sm-10"> <div class="title">3D Visual Discomfort Predictor Based on Neural Activity Statistics</div> <div class="author"> Heeseok Oh, <em>Jongyoo Kim</em>, Sanghoon Lee, and Alan C Bovik </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> , Dec 2015 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"><li> <div class="row"> <div id="kimQualityAssessmentPerceptual2014" class="col-sm-10"> <div class="title">Quality Assessment of Perceptual Crosstalk in Autostereoscopic Display</div> <div class="author"> <em>Jongyoo Kim</em>, Taewan Kim, and Sanghoon Lee </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> , Dec 2014 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Multimedia AI Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>